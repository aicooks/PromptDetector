import json
import os
import sys
import tempfile
from typing import Any, Dict, List, Optional

import streamlit as st

try:
    from docx import Document
except Exception:  # pragma: no cover - optional dependency
    Document = None

try:
    from pypdf import PdfReader
except Exception:  # pragma: no cover - optional dependency
    PdfReader = None

try:
    from faster_whisper import WhisperModel
except Exception:  # pragma: no cover - optional dependency
    WhisperModel = None

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(PROJECT_ROOT, "src"))

from prompt_detector.detector import analyze  # noqa: E402

SAMPLES_PATH = os.path.join(
    PROJECT_ROOT, "src", "prompt_detector", "data", "samples.json"
)
WHISPER_MODEL_NAME = os.getenv("PROMPTDETECTOR_WHISPER_MODEL", "small")
WHISPER_MODEL_DIR = os.getenv("PROMPTDETECTOR_WHISPER_MODEL_DIR")


def load_samples() -> List[Dict[str, str]]:
    with open(SAMPLES_PATH, "r", encoding="utf-8") as handle:
        return json.load(handle)


def _read_txt(uploaded) -> str:
    return uploaded.getvalue().decode("utf-8", errors="ignore")


def _read_pdf(uploaded) -> str:
    if PdfReader is None:
        return ""
    reader = PdfReader(uploaded)
    pages = [page.extract_text() or "" for page in reader.pages]
    return "\n".join(pages)


def _read_docx(uploaded) -> str:
    if Document is None:
        return ""
    doc = Document(uploaded)
    return "\n".join(paragraph.text for paragraph in doc.paragraphs)


def extract_text_from_upload(uploaded) -> Optional[str]:
    if not uploaded:
        return None
    name = uploaded.name.lower()
    if name.endswith(".txt"):
        return _read_txt(uploaded)
    if name.endswith(".pdf"):
        return _read_pdf(uploaded)
    if name.endswith(".docx"):
        return _read_docx(uploaded)
    return None


@st.cache_resource(show_spinner=False)
def get_whisper_model() -> Optional[Any]:
    if WhisperModel is None:
        return None
    if WHISPER_MODEL_DIR:
        return WhisperModel(WHISPER_MODEL_NAME, download_root=WHISPER_MODEL_DIR)
    return WhisperModel(WHISPER_MODEL_NAME)


def transcribe_audio(uploaded) -> Optional[str]:
    if WhisperModel is None:
        return None
    model = get_whisper_model()
    if model is None:
        return None

    suffix = os.path.splitext(uploaded.name)[-1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded.getvalue())
        tmp_path = tmp.name

    try:
        segments, _info = model.transcribe(tmp_path)
        return " ".join(segment.text.strip() for segment in segments if segment.text)
    finally:
        try:
            os.remove(tmp_path)
        except OSError:
            pass


def main() -> None:
    st.set_page_config(page_title="PromptDetector", page_icon="ğŸ›¡ï¸", layout="wide")
    st.title("ğŸ›¡ï¸ PromptDetectorï¼šæ³¨å…¥/è¶Šç‹±æ£€æµ‹æ¼”ç¤ºå°")
    st.caption("ä»…ç”¨äºé˜²æŠ¤ä¸æµ‹è¯•ï¼Œè¯·å‹¿ç”¨äºæ”»å‡»è¡Œä¸ºã€‚")

    samples = load_samples()
    sample_options = [f"{sample['id']:02d} Â· {sample['title']}" for sample in samples]

    if "prompt_text" not in st.session_state:
        st.session_state.prompt_text = ""
    if "doc_uploader_key" not in st.session_state:
        st.session_state.doc_uploader_key = 0
    if "audio_uploader_key" not in st.session_state:
        st.session_state.audio_uploader_key = 0

    left, right = st.columns([1.1, 1])

    with left:
        st.subheader("è¾“å…¥åŒºåŸŸ")
        selected = st.selectbox("é€‰æ‹©æµ‹è¯•æ ·ä¾‹", options=sample_options)
        if st.button("åŠ è½½æ ·ä¾‹", use_container_width=True):
            index = sample_options.index(selected)
            st.session_state.prompt_text = samples[index]["text"]

        uploaded_docs = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£ï¼ˆæ”¯æŒ .txt / .pdf / .docxï¼Œå¯å¤šé€‰ï¼‰",
            type=["txt", "pdf", "docx"],
            accept_multiple_files=True,
            key=f"doc_uploader_{st.session_state.doc_uploader_key}",
        )
        uploaded_audio = st.file_uploader(
            "ä¸Šä¼ è¯­éŸ³ï¼ˆæ”¯æŒ .wav / .mp3 / .m4aï¼Œå¯å¤šé€‰ï¼‰",
            type=["wav", "mp3", "m4a"],
            accept_multiple_files=True,
            key=f"audio_uploader_{st.session_state.audio_uploader_key}",
        )

        if uploaded_docs or uploaded_audio:
            combined_chunks: List[str] = []

            if uploaded_docs:
                for uploaded in uploaded_docs:
                    extracted = extract_text_from_upload(uploaded)
                    if extracted is None:
                        st.warning(f"{uploaded.name} æ— æ³•è¯»å–ã€‚")
                    elif not extracted.strip():
                        st.warning(f"{uploaded.name} å†…å®¹ä¸ºç©ºã€‚")
                    else:
                        combined_chunks.append(f"[æ–‡æ¡£:{uploaded.name}]\n{extracted}")

            if uploaded_audio:
                for audio in uploaded_audio:
                    with st.spinner(f"æ­£åœ¨è½¬å†™è¯­éŸ³ï¼š{audio.name} â€¦"):
                        transcript = transcribe_audio(audio)
                    if transcript is None:
                        st.warning(f"{audio.name} è½¬å†™ä¸å¯ç”¨ï¼Œè¯·ç¡®è®¤å·²å®‰è£… faster-whisper ä¸ä¾èµ–ã€‚")
                    elif not transcript.strip():
                        st.warning(f"{audio.name} æœªè¯†åˆ«å‡ºå†…å®¹ã€‚")
                    else:
                        combined_chunks.append(f"[è¯­éŸ³:{audio.name}]\n{transcript}")

            if combined_chunks:
                st.session_state.prompt_text = "\n\n".join(combined_chunks)
                st.success("æ–‡ä»¶å†…å®¹å·²åˆå¹¶å¹¶åŠ è½½åˆ°è¾“å…¥æ¡†ã€‚")

        st.session_state.prompt_text = st.text_area(
            "Prompt / å¯¹è¯å†…å®¹",
            height=240,
            value=st.session_state.prompt_text,
            placeholder="åœ¨æ­¤è¾“å…¥ prompt æˆ–å¯¹è¯å†…å®¹â€¦",
        )

        col_run, col_clear = st.columns([1, 1])
        run = col_run.button("è¿è¡Œæ£€æµ‹", type="primary", use_container_width=True)
        if col_clear.button("æ¸…ç©ºè¾“å…¥ä¸æ–‡ä»¶", use_container_width=True):
            st.session_state.prompt_text = ""
            st.session_state.doc_uploader_key += 1
            st.session_state.audio_uploader_key += 1
            st.rerun()

    with right:
        st.subheader("æ£€æµ‹ç»“æœ")
        if run:
            result = analyze(st.session_state.prompt_text)
            score = result["risk_score"]
            action = result["action"]
            st.metric("é£é™©åˆ†æ•°", f"{score}/100")
            st.progress(score / 100)

            if action == "æ‹’ç»":
                st.error("å»ºè®®å¤„ç½®ï¼šæ‹’ç»")
            elif action == "äºŒæ¬¡ç¡®è®¤":
                st.warning("å»ºè®®å¤„ç½®ï¼šäºŒæ¬¡ç¡®è®¤")
            else:
                st.success("å»ºè®®å¤„ç½®ï¼šå…è®¸")

            st.write(result["summary"])

            guardrails_detail = result.get("guardrails", {"enabled": False})
            if guardrails_detail.get("enabled"):
                with st.expander("Guardrails æ£€æµ‹è¯¦æƒ…", expanded=False):
                    st.json(guardrails_detail)

            if result["matched_rules"]:
                st.markdown("### å‘½ä¸­è§„åˆ™")
                st.dataframe(
                    [
                        {
                            "è§„åˆ™": rule["name"],
                            "æƒé‡": rule["weight"],
                            "æ ‡ç­¾": ", ".join(rule["tags"]),
                            "ç‰‡æ®µ": rule["snippet"],
                        }
                        for rule in result["matched_rules"]
                    ],
                    use_container_width=True,
                )
            else:
                st.info("æœªå‘½ä¸­è§„åˆ™ï¼Œå¯èƒ½æ˜¯æ­£å¸¸è¾“å…¥ã€‚")
        else:
            st.info("é€‰æ‹©æ ·ä¾‹æˆ–è¾“å…¥å†…å®¹åç‚¹å‡»â€œè¿è¡Œæ£€æµ‹â€ã€‚")


if __name__ == "__main__":
    main()
